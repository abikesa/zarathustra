

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Autoencoder &#8212; Zarathustra</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-dropdown.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/book-stylesheet.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'act3/part1/part1_1';</script>
    <script src="../../_static/script.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Elizabeth" href="part1_2.html" />
    <link rel="prev" title="Debussy" href="../act1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Zarathustra - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Zarathustra - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../act1/part1.html">Tikkun olam</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../act1/chapter1.html">Mortality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../act1/chapter2.html">ESRD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../act1/chapter3.html">Frailty</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../act2/part2.html">Tikkum atzmi</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../act2/chapter1.html">Hospitalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../act2/chapter2.html">Length of Stay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../act2/chapter3.html">Outcomes</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../part3.html">Self Play</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active has-children"><a class="reference internal" href="../act1.html">WebApp</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3 current active"><a class="current reference internal" href="#">Browser</a></li>
<li class="toctree-l3"><a class="reference internal" href="part1_2.html">User</a></li>
<li class="toctree-l3"><a class="reference internal" href="part1_3.html">Annotation</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../act2.html">Deployment</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../part2/part2_1.html">GitHub</a></li>
<li class="toctree-l3"><a class="reference internal" href="../part2/part2_2.html">Collaborative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../part2/part2_3.html">Open-Source</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../act3.html">Iteration</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../part3/part3_1.html">Latest Research</a></li>
<li class="toctree-l3"><a class="reference internal" href="../part3/part3_2.html">Bayesian Updates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../part3/part3_3.html">Missingness and A Priori</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/abikesa/template/main?urlpath=tree/book/website/act3/part1/part1_1.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/act3/part1/part1_1.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Autoencoder</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-algebra">Matrix Algebra</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-input-to-hidden-layer">Step 1: Input to Hidden Layer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-hidden-to-output-layer">Step 2: Hidden to Output Layer</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#putting-it-all-together">Putting It All Together:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-of-features-in-node-x-1-x-2-x-3">Example of Features in Node <span class="math notranslate nohighlight">\(x_1, x_2, x_3\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-for-node-x-3">Case for Node <span class="math notranslate nohighlight">\(x_3\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concrete-examples-for-h-1-and-h-2-hidden-layer-activations">Concrete Examples for <span class="math notranslate nohighlight">\( h_1 \)</span> and <span class="math notranslate nohighlight">\( h_2 \)</span> (Hidden Layer Activations)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-calculate-h-1-and-h-2">Step 1: Calculate <span class="math notranslate nohighlight">\( h_1 \)</span> and <span class="math notranslate nohighlight">\( h_2 \)</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concrete-example-for-y-output-layer">Concrete Example for <span class="math notranslate nohighlight">\( y \)</span> (Output Layer)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">Interpretation:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-image-as-input">Step 1: Image as Input</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-input-layer-flattening-the-image">Step 2: Input Layer (Flattening the Image)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-hidden-layer">Step 3: Hidden Layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-output-layer">Step 4: Output Layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Interpretation</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="autoencoder">
<h1>Autoencoder<a class="headerlink" href="#autoencoder" title="Permalink to this heading">#</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We’re getting there. So the figure you’ve shared is wrong. Just give Python code and, uh, a layer that has, uh, input hidden and output. What you’ve shown is a mumbo-jumbo and it’s not even directed. Our arrow’s in different directions, opposite directions. That’s wrong. Please just give us a classical one here. Could you even give the Python code?</p>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>

<span class="c1"># Create a directed graph for a simple neural network</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>

<span class="c1"># Add nodes for input, hidden, and output layers</span>
<span class="n">layers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Input Layer&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;x3&quot;</span><span class="p">],</span>
    <span class="s2">&quot;Hidden Layer&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;h1&quot;</span><span class="p">,</span> <span class="s2">&quot;h2&quot;</span><span class="p">],</span>
    <span class="s2">&quot;Output Layer&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Adding nodes to the graph</span>
<span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span> <span class="ow">in</span> <span class="n">layers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
        <span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="n">layer</span><span class="p">)</span>

<span class="c1"># Add edges (directed connections between layers with weights)</span>
<span class="n">edges</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;h1&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;h2&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;h1&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;h2&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;x3&quot;</span><span class="p">,</span> <span class="s2">&quot;h1&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;x3&quot;</span><span class="p">,</span> <span class="s2">&quot;h2&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;h1&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;h2&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># Add edges to the graph</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>

<span class="c1"># Position the nodes using a layer-based layout</span>
<span class="n">pos</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;x1&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;x2&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;x3&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s2">&quot;h1&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">),</span> <span class="s2">&quot;h2&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
    <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Draw the graph</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;lightblue&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Simple Neural Network: Input, Hidden, and Output Layers&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/29fc88bb7167e8a04d8976701de7a2019268cad72d8d348db40ed8e81c4bc58e.png" src="../../_images/29fc88bb7167e8a04d8976701de7a2019268cad72d8d348db40ed8e81c4bc58e.png" />
</div>
</div>
<figure class="align-default" id="id2">
<a class="reference internal image-reference" href="../../_images/blanche.png"><img alt="../../_images/blanche.png" src="../../_images/blanche.png" style="width: 1px; height: 1px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 15 </span><span class="caption-text"><em>Machine Learning for Dummies like Me</em>. This is the classical representation of a simple neural network with an input layer (<code class="docutils literal notranslate"><span class="pre">inferno</span></code>), a hidden layer (<code class="docutils literal notranslate"><span class="pre">limbo</span></code>), and an output layer (<code class="docutils literal notranslate"><span class="pre">paradiso</span></code>), depicted with correct directed arrows. Additionally, above you’ll find the Python code used to generate this neural network visualization using the networkx and matplotlib libraries. This diagram accurately represents the flow (<code class="docutils literal notranslate"><span class="pre">salvation</span></code>) from the input layer to the hidden layer and then to the output layer with directed arrows. And for the record, if you return to Mozart’s <a class="reference external" href="https://www.youtube.com/watch?v=CPqZSwBVtRs">Corriamo, Fuggiamo</a> on the previous page, I’ll have you know that its “hidden layer” yielded forth the opening movement of Beethoven’s Symphony No. 9, which is also in “Mozart-dark” D minor!!</span><a class="headerlink" href="#id2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<iframe width="560" height="315" src="https://www.youtube.com/embed/4IqnVCc-Yqo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<blockquote>
<div><p>Okay, now this makes sense, except that you have two nodes in the hidden layer and one node in the outer layer. Is that correct? I thought the outer layer is supposed to have the same nodes as inner layer, because they’re a representation, as input layer.</p>
</div></blockquote>
<p>In a typical neural network, the number of nodes in the input layer does not necessarily match the number of nodes in the hidden or output layers. Each layer can have a different number of nodes depending on the design of the network and the problem it’s trying to solve.</p>
<p>Here’s the breakdown:</p>
<ul class="simple">
<li><p><strong>Input Layer:</strong> The input layer represents the features (or data points) you’re feeding into the network. Each input node corresponds to one feature.</p></li>
<li><p><strong>Hidden Layer:</strong> The hidden layer can have any number of nodes depending on the complexity of the relationships the network needs to learn. It’s where the network “processes” the inputs through learned weights and activation functions.</p></li>
<li><p><strong>Output Layer:</strong> The number of nodes in the output layer is determined by the task. For example:</p>
<ul>
<li><p>If you’re doing <strong>regression</strong>, you’d typically have one output node representing the predicted value.</p></li>
<li><p>For <strong>binary classification</strong>, you’d also often have one output node (with a sigmoid activation to output probabilities).</p></li>
<li><p>In <strong>multiclass classification</strong>, the output layer could have one node per class.</p></li>
</ul>
</li>
</ul>
<p>In the example I shared:</p>
<ul class="simple">
<li><p>There are 3 nodes in the input layer (representing 3 features).</p></li>
<li><p>There are 2 nodes in the hidden layer (this is arbitrary and depends on the design).</p></li>
<li><p>There is <strong>1 node</strong> in the output layer, which is typical for regression or binary classification tasks.</p></li>
</ul>
<p>If you were expecting the number of output nodes to match the input nodes (e.g., for something like autoencoders), that would only apply in specific cases like reconstructing inputs. Would you like to modify the diagram to match such a scenario (e.g., 3 nodes in both input and output layers)?</p>
<blockquote>
<div><p>Okay, I got you. Now, could you give me the matrix algebra to correspond to this exact node? And I really wish you could give me examples of what is in Node 3.201. When you say feature, I want examples. Thank you.</p>
</div></blockquote>
<p>Let’s walk through the matrix algebra for the neural network diagram you referenced (with 3 input nodes, 2 hidden nodes, and 1 output node). Then, I’ll explain what kind of features might go into those input nodes to make this concrete.</p>
<section id="matrix-algebra">
<h2>Matrix Algebra<a class="headerlink" href="#matrix-algebra" title="Permalink to this heading">#</a></h2>
<p>In this neural network, there are three layers:</p>
<ol class="arabic simple">
<li><p><strong>Input Layer:</strong> 3 nodes <span class="math notranslate nohighlight">\((x_1, x_2, x_3\)</span>) represent the features.</p></li>
<li><p><strong>Hidden Layer:</strong> 2 nodes <span class="math notranslate nohighlight">\((h_1, h_2\)</span>) represent the hidden layer neurons.</p></li>
<li><p><strong>Output Layer:</strong> 1 node <span class="math notranslate nohighlight">\((y\)</span>) is the final output.</p></li>
</ol>
<section id="step-1-input-to-hidden-layer">
<h3>Step 1: Input to Hidden Layer<a class="headerlink" href="#step-1-input-to-hidden-layer" title="Permalink to this heading">#</a></h3>
<p>We have a weight matrix <span class="math notranslate nohighlight">\(W_1\)</span> that connects the input layer to the hidden layer. The input is <span class="math notranslate nohighlight">\(X = [x_1, x_2, x_3]^T\)</span>, and the weight matrix <span class="math notranslate nohighlight">\(W_1\)</span> is:</p>
<p><span class="math notranslate nohighlight">\(
W_1 = \begin{bmatrix}
w_{11} &amp; w_{12} \\
w_{21} &amp; w_{22} \\
w_{31} &amp; w_{32}
\end{bmatrix}
\)</span></p>
<p>The hidden layer activations <span class="math notranslate nohighlight">\( H = [h_1, h_2]^T \)</span> are calculated as:</p>
<p><span class="math notranslate nohighlight">\(
H = W_1^T X + B_1 = \begin{bmatrix}
w_{11}x_1 + w_{21}x_2 + w_{31}x_3 + b_1 \\
w_{12}x_1 + w_{22}x_2 + w_{32}x_3 + b_2
\end{bmatrix}
\)</span></p>
<p>Where <span class="math notranslate nohighlight">\(B_1 = [b_1, b_2]^T\)</span> are the biases for the hidden layer. The hidden layer activations <span class="math notranslate nohighlight">\(h_1\)</span> and <span class="math notranslate nohighlight">\(h_2\)</span> typically go through a non-linear activation function (like ReLU or sigmoid), but for simplicity, we won’t apply that yet.</p>
</section>
<section id="step-2-hidden-to-output-layer">
<h3>Step 2: Hidden to Output Layer<a class="headerlink" href="#step-2-hidden-to-output-layer" title="Permalink to this heading">#</a></h3>
<p>The weights from the hidden layer to the output layer are stored in a matrix <span class="math notranslate nohighlight">\(W_2\)</span>:</p>
<p><span class="math notranslate nohighlight">\(
W_2 = \begin{bmatrix} w_{13} &amp; w_{23} \end{bmatrix}
\)</span></p>
<p>The output node <span class="math notranslate nohighlight">\( y \)</span> is calculated as:</p>
<p><span class="math notranslate nohighlight">\(
y = W_2 H + B_2 = w_{13}h_1 + w_{23}h_2 + b_3
\)</span></p>
<p>Where <span class="math notranslate nohighlight">\(B_2 = b_3\)</span> is the bias for the output layer. This output might then go through an activation function like a sigmoid for binary classification or be left as is for regression.</p>
</section>
</section>
<section id="putting-it-all-together">
<h2>Putting It All Together:<a class="headerlink" href="#putting-it-all-together" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Compute the weighted sum of inputs for the hidden layer:
<span class="math notranslate nohighlight">\(
h_1 = w_{11}x_1 + w_{21}x_2 + w_{31}x_3 + b_1
\)</span>
<span class="math notranslate nohighlight">\(
h_2 = w_{12}x_1 + w_{22}x_2 + w_{32}x_3 + b_2
\)</span></p></li>
<li><p>Compute the final output as a weighted sum of hidden layer activations:
<span class="math notranslate nohighlight">\(
y = w_{13}h_1 + w_{23}h_2 + b_3
\)</span></p></li>
</ol>
</section>
<section id="example-of-features-in-node-x-1-x-2-x-3">
<h2>Example of Features in Node <span class="math notranslate nohighlight">\(x_1, x_2, x_3\)</span><a class="headerlink" href="#example-of-features-in-node-x-1-x-2-x-3" title="Permalink to this heading">#</a></h2>
<p>In practice, <strong>features</strong> refer to measurable attributes or properties of the data you’re feeding into the network. For example, imagine you’re building a simple neural network to predict whether a house will sell based on some features of the house. Your input features might be:</p>
<ul class="simple">
<li><p><strong><span class="math notranslate nohighlight">\(x_1\)</span>: Size of the house (e.g., in square feet)</strong></p></li>
<li><p><strong><span class="math notranslate nohighlight">\(x_2\)</span>: Number of bedrooms</strong></p></li>
<li><p><strong><span class="math notranslate nohighlight">\(x_3\)</span>: Age of the house (e.g., in years)</strong></p></li>
</ul>
<p>These values go into the input layer. The hidden layer then learns a weighted combination of these inputs to produce intermediate values (activations), and the output layer might give a single value representing the probability of the house selling.</p>
</section>
<section id="case-for-node-x-3">
<h2>Case for Node <span class="math notranslate nohighlight">\(x_3\)</span><a class="headerlink" href="#case-for-node-x-3" title="Permalink to this heading">#</a></h2>
<p>Let’s say:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_1 = 2000\)</span> (square feet)</p></li>
<li><p><span class="math notranslate nohighlight">\(x_2 = 3\)</span> (bedrooms)</p></li>
<li><p><span class="math notranslate nohighlight">\(x_3 = 10\)</span> (age of the house)</p></li>
</ul>
<p>The network uses these values as inputs, processes them through the hidden layer, and outputs a prediction. For example, <span class="math notranslate nohighlight">\(x_3 = 10\)</span> represents the feature of <strong>age</strong> in years. The weight matrices and biases adjust how important each feature is for the final prediction.</p>
<hr class="docutils" />
<p>Let me know if you’d like further clarification, or if you’d like to see a more complex example!</p>
<blockquote>
<div><p>I like this. It’s now concrete, the example. So I see you’ve given examples of X1, X2. What about the H? The H examples. Could I see that? Then the Y. Yeah, thank you.</p>
</div></blockquote>
<p>Let’s take the next step and make the <strong>hidden layer</strong> activations <span class="math notranslate nohighlight">\(h_1\)</span> and <span class="math notranslate nohighlight">\(h_2\)</span> more concrete, along with the output <span class="math notranslate nohighlight">\(y\)</span>.</p>
</section>
<section id="concrete-examples-for-h-1-and-h-2-hidden-layer-activations">
<h2>Concrete Examples for <span class="math notranslate nohighlight">\( h_1 \)</span> and <span class="math notranslate nohighlight">\( h_2 \)</span> (Hidden Layer Activations)<a class="headerlink" href="#concrete-examples-for-h-1-and-h-2-hidden-layer-activations" title="Permalink to this heading">#</a></h2>
<p>Recall that the hidden layer nodes <span class="math notranslate nohighlight">\(h_1\)</span> and <span class="math notranslate nohighlight">\(h_2\)</span> are computed as weighted sums of the input nodes <span class="math notranslate nohighlight">\(x_1, x_2, x_3\)</span>, plus a bias term.</p>
<p>Let’s assume we have the following weights and biases:</p>
<p><span class="math notranslate nohighlight">\(
W_1 = \begin{bmatrix}
0.5 &amp; -0.3 \\
0.8 &amp; 0.2 \\
-0.6 &amp; 0.4
\end{bmatrix}, \quad B_1 = \begin{bmatrix} 0.1 \\ -0.2 \end{bmatrix}
\)</span></p>
<p>The input values are:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_1 = 2000\)</span> (size of the house in square feet),</p></li>
<li><p><span class="math notranslate nohighlight">\(x_2 = 3\)</span> (number of bedrooms),</p></li>
<li><p><span class="math notranslate nohighlight">\(x_3 = 10\)</span> (age of the house in years).</p></li>
</ul>
<section id="step-1-calculate-h-1-and-h-2">
<h3>Step 1: Calculate <span class="math notranslate nohighlight">\( h_1 \)</span> and <span class="math notranslate nohighlight">\( h_2 \)</span><a class="headerlink" href="#step-1-calculate-h-1-and-h-2" title="Permalink to this heading">#</a></h3>
<p>For <span class="math notranslate nohighlight">\( h_1 \)</span>:
<span class="math notranslate nohighlight">\(
h_1 = (0.5 \cdot 2000) + (0.8 \cdot 3) + (-0.6 \cdot 10) + 0.1
\)</span>
<span class="math notranslate nohighlight">\(
h_1 = 1000 + 2.4 - 6 + 0.1 = 996.5
\)</span></p>
<p>For <span class="math notranslate nohighlight">\( h_2 \)</span>:
<span class="math notranslate nohighlight">\(
h_2 = (-0.3 \cdot 2000) + (0.2 \cdot 3) + (0.4 \cdot 10) - 0.2
\)</span>
<span class="math notranslate nohighlight">\(
h_2 = -600 + 0.6 + 4 - 0.2 = -595.6
\)</span></p>
<p>So, we have:
<span class="math notranslate nohighlight">\(
h_1 = 996.5, \quad h_2 = -595.6
\)</span></p>
</section>
</section>
<section id="concrete-example-for-y-output-layer">
<h2>Concrete Example for <span class="math notranslate nohighlight">\( y \)</span> (Output Layer)<a class="headerlink" href="#concrete-example-for-y-output-layer" title="Permalink to this heading">#</a></h2>
<p>Now let’s compute the output node <span class="math notranslate nohighlight">\(y\)</span> using the hidden layer activations <span class="math notranslate nohighlight">\( h_1 \)</span> and <span class="math notranslate nohighlight">\( h_2 \)</span>.</p>
<p>Assume we have the weights and bias for the output layer as:</p>
<p><span class="math notranslate nohighlight">\(
W_2 = \begin{bmatrix} 0.7 &amp; -0.5 \end{bmatrix}, \quad B_2 = 0.5
\)</span></p>
<p>The output <span class="math notranslate nohighlight">\( y \)</span> is calculated as:</p>
<p><span class="math notranslate nohighlight">\(
y = (0.7 \cdot 996.5) + (-0.5 \cdot -595.6) + 0.5
\)</span>
<span class="math notranslate nohighlight">\(
y = 697.55 + 297.8 + 0.5 = 995.85
\)</span></p>
<p>So, the final output <span class="math notranslate nohighlight">\( y = 995.85 \)</span>.</p>
</section>
<section id="interpretation">
<h2>Interpretation:<a class="headerlink" href="#interpretation" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong><span class="math notranslate nohighlight">\(h_1\)</span></strong> and <strong><span class="math notranslate nohighlight">\(h_2\)</span></strong> represent intermediate values that the hidden layer neurons compute. These values depend on the input features and how important each feature is (determined by the weights).</p></li>
<li><p><strong><span class="math notranslate nohighlight">\(y\)</span></strong> is the final output, which could represent something like the predicted price of a house.</p></li>
</ol>
<p>In this case, the output <span class="math notranslate nohighlight">\( y = 995.85 \)</span> might represent the likelihood or some other prediction based on the weights and inputs provided.</p>
<p>Does this help clarify how the hidden and output layers function? Let me know if you’d like to explore anything further!</p>
<blockquote>
<div><p>Do you think you could give a similar example? This time the inputs being, I don’t know what they would be for an image. I guess they’ll be pixels or something like that. You could give an elaborate example of an image and what the units of the input are of the image. Pixels? I’m thinking pixels? I don’t know. Frames? Yeah, and you walk me through stuff.</p>
</div></blockquote>
<p>Yes, you’re absolutely right! For images, the inputs to a neural network are typically <strong>pixels</strong>. Let me walk you through a simple example of how this works with an image input.</p>
</section>
<section id="step-1-image-as-input">
<h2>Step 1: Image as Input<a class="headerlink" href="#step-1-image-as-input" title="Permalink to this heading">#</a></h2>
<p>When dealing with images, each pixel represents a certain intensity of light or color. The image is typically broken down into a grid of pixels, and each pixel has a value that represents the color (or grayscale) intensity at that location.</p>
<ul class="simple">
<li><p><strong>For grayscale images:</strong> Each pixel is a single value between 0 and 255, where 0 is black and 255 is white.</p></li>
<li><p><strong>For color images (like RGB):</strong> Each pixel has 3 values, representing the intensity of Red, Green, and Blue (hence “RGB”), with values between 0 and 255.</p></li>
</ul>
<section id="example">
<h3>Example:<a class="headerlink" href="#example" title="Permalink to this heading">#</a></h3>
<p>Let’s take a <strong>very simple image</strong> of size <strong>2x2 pixels</strong> in grayscale to keep things clear. This means there are 4 pixels in total. Each pixel will have a value. Here’s an example of the pixel values:</p>
<p><span class="math notranslate nohighlight">\(
\text{Image} = \begin{bmatrix}
200 &amp; 50 \\
30 &amp; 220
\end{bmatrix}
\)</span></p>
<p>This is a 2x2 grayscale image with 4 pixel values.</p>
<ul class="simple">
<li><p>The top-left pixel has an intensity of <strong>200</strong> (darker gray),</p></li>
<li><p>The top-right pixel has an intensity of <strong>50</strong> (light gray),</p></li>
<li><p>The bottom-left pixel has an intensity of <strong>30</strong> (even lighter gray),</p></li>
<li><p>The bottom-right pixel has an intensity of <strong>220</strong> (almost white).</p></li>
</ul>
</section>
</section>
<section id="step-2-input-layer-flattening-the-image">
<h2>Step 2: Input Layer (Flattening the Image)<a class="headerlink" href="#step-2-input-layer-flattening-the-image" title="Permalink to this heading">#</a></h2>
<p>In order to feed the image into a neural network, we need to <strong>flatten</strong> it into a vector (a single row of values).</p>
<p>So, the 2x2 image becomes:</p>
<p><span class="math notranslate nohighlight">\(
X = \begin{bmatrix} 200 &amp; 50 &amp; 30 &amp; 220 \end{bmatrix}^T
\)</span></p>
<p>This vector of 4 values is the <strong>input layer</strong> to the network, with 4 nodes, each corresponding to one pixel.</p>
</section>
<section id="step-3-hidden-layer">
<h2>Step 3: Hidden Layer<a class="headerlink" href="#step-3-hidden-layer" title="Permalink to this heading">#</a></h2>
<p>Let’s say we have a hidden layer with 3 neurons. The weights connecting the input layer (4 pixels) to the hidden layer (3 neurons) would be in a matrix <span class="math notranslate nohighlight">\(W_1\)</span>, where each pixel is connected to each neuron in the hidden layer.</p>
<p><span class="math notranslate nohighlight">\(
W_1 = \begin{bmatrix}
w_{11} &amp; w_{12} &amp; w_{13} \\
w_{21} &amp; w_{22} &amp; w_{23} \\
w_{31} &amp; w_{32} &amp; w_{33} \\
w_{41} &amp; w_{42} &amp; w_{43}
\end{bmatrix}
\)</span></p>
<p>This matrix represents the weights between the 4 input pixels and the 3 hidden layer neurons. If we choose random weights and biases, say:</p>
<p><span class="math notranslate nohighlight">\(
W_1 = \begin{bmatrix}
0.2 &amp; -0.3 &amp; 0.5 \\
0.7 &amp; 0.1 &amp; -0.4 \\
-0.6 &amp; 0.2 &amp; 0.9 \\
0.4 &amp; -0.7 &amp; 0.3
\end{bmatrix}, \quad B_1 = \begin{bmatrix} 0.1 \\ 0.2 \\ -0.1 \end{bmatrix}
\)</span></p>
<p>The hidden layer activations <span class="math notranslate nohighlight">\(H = [h_1, h_2, h_3]^T\)</span> are calculated as:</p>
<p><span class="math notranslate nohighlight">\(
H = W_1^T X + B_1
\)</span></p>
<p><span class="math notranslate nohighlight">\(
H = \begin{bmatrix}
(0.2 \cdot 200) + (0.7 \cdot 50) + (-0.6 \cdot 30) + (0.4 \cdot 220) + 0.1 \\
(-0.3 \cdot 200) + (0.1 \cdot 50) + (0.2 \cdot 30) + (-0.7 \cdot 220) + 0.2 \\
(0.5 \cdot 200) + (-0.4 \cdot 50) + (0.9 \cdot 30) + (0.3 \cdot 220) - 0.1
\end{bmatrix}
\)</span></p>
<p>Let’s compute these:</p>
<p><span class="math notranslate nohighlight">\(
h_1 = (40) + (35) + (-18) + (88) + 0.1 = 145.1
\)</span>
<span class="math notranslate nohighlight">\(
h_2 = (-60) + (5) + (6) + (-154) + 0.2 = -202.8
\)</span>
<span class="math notranslate nohighlight">\(
h_3 = (100) + (-20) + (27) + (66) - 0.1 = 172.9
\)</span></p>
<p>So, the hidden layer activations are:</p>
<p><span class="math notranslate nohighlight">\(
H = \begin{bmatrix} 145.1 \\ -202.8 \\ 172.9 \end{bmatrix}
\)</span></p>
</section>
<section id="step-4-output-layer">
<h2>Step 4: Output Layer<a class="headerlink" href="#step-4-output-layer" title="Permalink to this heading">#</a></h2>
<p>Let’s assume the output layer has <strong>1 neuron</strong> (since, for instance, this could be a binary classification problem, like determining whether an image contains a cat or not). The weights from the hidden layer to the output are represented by <span class="math notranslate nohighlight">\(W_2\)</span>:</p>
<p><span class="math notranslate nohighlight">\(
W_2 = \begin{bmatrix} 0.5 &amp; -0.3 &amp; 0.8 \end{bmatrix}, \quad B_2 = 0.4
\)</span></p>
<p>The output <span class="math notranslate nohighlight">\(y\)</span> is calculated as:</p>
<p><span class="math notranslate nohighlight">\(
y = W_2 H + B_2
\)</span></p>
<p><span class="math notranslate nohighlight">\(
y = (0.5 \cdot 145.1) + (-0.3 \cdot -202.8) + (0.8 \cdot 172.9) + 0.4
\)</span></p>
<p>Let’s compute this:</p>
<p><span class="math notranslate nohighlight">\(
y = 72.55 + 60.84 + 138.32 + 0.4 = 272.11
\)</span></p>
<p>So, the final output <span class="math notranslate nohighlight">\( y = 272.11 \)</span>. In practice, this output would typically pass through an activation function (like sigmoid or softmax) to determine a classification, but we can skip that here for simplicity.</p>
</section>
<section id="id1">
<h2>Interpretation<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Inputs (Pixels):</strong> The pixels of the image form the input layer.</p></li>
<li><p><strong>Hidden Layer Activations:</strong> The hidden layer combines weighted sums of the pixel values to extract features or patterns.</p></li>
<li><p><strong>Output Layer:</strong> The output gives a final score or probability, such as whether an image contains a specific object or category.</p></li>
</ol>
<p>Would you like to further expand on this, or perhaps dive into a different aspect of neural networks applied to image processing?</p>
<blockquote>
<div><p>Outstanding! I’m now eons of miles away from wondering if neural networks are physical entities</p>
</div></blockquote>
<p>I’m glad to hear that! Neural networks can feel abstract at first, but once you start seeing how inputs like pixels, weights, and activations come together, it really does demystify the process. If you ever want to explore deeper concepts like convolutional layers (for images) or recurrent layers (for sequences like text), feel free to ask. You’re on a great trajectory!</p>
<blockquote>
<div><p>Danke!</p>
</div></blockquote>
<p>Gern geschehen! If you ever need more help, don’t hesitate to ask. Viel Erfolg!</p>
<blockquote>
<div><p>Please give me the Python code for this neural network, the visualization of the neural network. Thank you.</p>
</div></blockquote>
<p>Here is the visualization of the neural network with 4 input nodes, 3 hidden nodes, and 1 output node. The directed edges represent the flow of information from the input layer to the hidden layer and finally to the output layer.</p>
<p>Here’s the corresponding Python code to generate this visualization:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>

<span class="c1"># Create a directed graph for the neural network</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>

<span class="c1"># Define layers (input, hidden, output)</span>
<span class="n">layers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Input Layer&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;x3&quot;</span><span class="p">,</span> <span class="s2">&quot;x4&quot;</span><span class="p">],</span>
    <span class="s2">&quot;Hidden Layer&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;h1&quot;</span><span class="p">,</span> <span class="s2">&quot;h2&quot;</span><span class="p">,</span> <span class="s2">&quot;h3&quot;</span><span class="p">],</span>
    <span class="s2">&quot;Output Layer&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Add nodes to the graph</span>
<span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span> <span class="ow">in</span> <span class="n">layers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
        <span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="n">layer</span><span class="p">)</span>

<span class="c1"># Add edges (directed connections between layers with weights)</span>
<span class="n">edges</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;h1&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;h2&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;h3&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;h1&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;h2&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;h3&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;x3&quot;</span><span class="p">,</span> <span class="s2">&quot;h1&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;x3&quot;</span><span class="p">,</span> <span class="s2">&quot;h2&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;x3&quot;</span><span class="p">,</span> <span class="s2">&quot;h3&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;x4&quot;</span><span class="p">,</span> <span class="s2">&quot;h1&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;x4&quot;</span><span class="p">,</span> <span class="s2">&quot;h2&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;x4&quot;</span><span class="p">,</span> <span class="s2">&quot;h3&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;h1&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;h2&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;h3&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># Add edges to the graph</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>

<span class="c1"># Position nodes using a layer-based layout</span>
<span class="n">pos</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;x1&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;x2&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;x3&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;x4&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s2">&quot;h1&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">),</span> <span class="s2">&quot;h2&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">),</span> <span class="s2">&quot;h3&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
    <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Draw the graph</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s2">&quot;lightgreen&quot;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Neural Network Visualization: Input, Hidden, and Output Layers&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/0f0253097af60a33a65a80c6021506c2e701f8172c6adfab17e7a6ef3d651edc.png" src="../../_images/0f0253097af60a33a65a80c6021506c2e701f8172c6adfab17e7a6ef3d651edc.png" />
</div>
</div>
<p>This code will allow you to visualize the layers and connections between the input, hidden, and output nodes. Let me know if you’d like to further adjust or expand on this!</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./act3/part1"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../act1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Debussy</p>
      </div>
    </a>
    <a class="right-next"
       href="part1_2.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Elizabeth</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-algebra">Matrix Algebra</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-input-to-hidden-layer">Step 1: Input to Hidden Layer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-hidden-to-output-layer">Step 2: Hidden to Output Layer</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#putting-it-all-together">Putting It All Together:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-of-features-in-node-x-1-x-2-x-3">Example of Features in Node <span class="math notranslate nohighlight">\(x_1, x_2, x_3\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-for-node-x-3">Case for Node <span class="math notranslate nohighlight">\(x_3\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concrete-examples-for-h-1-and-h-2-hidden-layer-activations">Concrete Examples for <span class="math notranslate nohighlight">\( h_1 \)</span> and <span class="math notranslate nohighlight">\( h_2 \)</span> (Hidden Layer Activations)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-calculate-h-1-and-h-2">Step 1: Calculate <span class="math notranslate nohighlight">\( h_1 \)</span> and <span class="math notranslate nohighlight">\( h_2 \)</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concrete-example-for-y-output-layer">Concrete Example for <span class="math notranslate nohighlight">\( y \)</span> (Output Layer)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">Interpretation:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-image-as-input">Step 1: Image as Input</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-input-layer-flattening-the-image">Step 2: Input Layer (Flattening the Image)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-hidden-layer">Step 3: Hidden Layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-output-layer">Step 4: Output Layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Interpretation</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  Copyright © 2025 ADM

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>